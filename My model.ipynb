{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surgical-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fitting-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "import glob\n",
    "\n",
    "blocked = glob.glob('dataset/Blocked/*.*')\n",
    "free = glob.glob('dataset/Free/*.*')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in blocked:   \n",
    "    image = tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size = (224,224))\n",
    "    image = np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in free:   \n",
    "    image = tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size = (224,224))\n",
    "    image = np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "    \n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "falling-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biological-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset 80/20 (x - data, y - labels)\n",
    "\n",
    "X_train, x_test, Y_train, y_test = train_test_split(data, labels, test_size = 0.2,\n",
    "                                                random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "supported-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 1)\n",
      "(29, 1)\n",
      "(112, 224, 224, 3)\n",
      "(29, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reshape labels as 2d-tensor (the first dim will is the batch dim and the second is the scalar label)\n",
    "\n",
    "Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(x_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applicable-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               6422656   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 6,451,554\n",
      "Trainable params: 6,451,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make the CNN model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3))) # Convolutional layer\n",
    "model.add(MaxPool2D()) # Pooling layer\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4)) # Randomly select 40% of the neurons and set their weights to 0 for one iteration\n",
    "                        # to prevent overfitting\n",
    "\n",
    "model.add(Flatten()) # Converts the pooled feature map to a single column \n",
    "                     # that is passed to the fully connected layer\n",
    "    \n",
    "model.add(Dense(128,activation=\"relu\")) # Fully connected layer\n",
    "model.add(Dense(2, activation=\"softmax\")) # Output layer\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-regular",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile the model (using Adam as optimizer and SparseCategoricalCrossentropy as the loss function)\n",
    "\n",
    "opt = Adam(lr = 0.001)\n",
    "model.compile(optimizer = opt, \n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Train model\n",
    "\n",
    "model_train = model.fit(X_train, Y_train, epochs = 6, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "loaded-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 93.1034505367279 %\n"
     ]
    }
   ],
   "source": [
    "# Estimate model\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"test accuracy {acc*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solar-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "model.save('best_model.h5')\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nonprofit-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.98 0.02]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.89 0.11]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.37 0.63]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "pred = model.predict(x_test)\n",
    "print(np.round(pred,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-constitution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
